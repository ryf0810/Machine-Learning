{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6a87448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... your code here ... (import statements)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90946b9",
   "metadata": {},
   "source": [
    "## 1. Feature engineering (one-hot encoding and data imputation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa128a8c",
   "metadata": {},
   "source": [
    "### Read the data from [http://www.stat.wisc.edu/~jgillett/451/data/kaggle_titanic_train.csv](http://www.stat.wisc.edu/~jgillett/451/data/kaggle_titanic_train.csv).\n",
    "- Retain only these columns: Survived, Pclass, Sex, Age, SibSp, Parch.\n",
    "- Display the first 7 rows.\n",
    "\n",
    "These data are described at [https://www.kaggle.com/competitions/titanic/data](https://www.kaggle.com/competitions/titanic/data) (click on \n",
    "\n",
    "We evaluate how these strategies can improve model performance by allowing us to use columns with categorical or missing data.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "700852b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 7 Rows: \n",
      "   Survived  Pclass     Sex   Age  SibSp  Parch\n",
      "0         0       3    male  22.0      1      0\n",
      "1         1       1  female  38.0      1      0\n",
      "2         1       3  female  26.0      0      0\n",
      "3         1       1  female  35.0      1      0\n",
      "4         0       3    male  35.0      0      0\n",
      "5         0       3    male   NaN      0      0\n",
      "6         0       1    male  54.0      0      0\n"
     ]
    }
   ],
   "source": [
    "# ... your code here ...\n",
    "df = pd.read_csv('http://www.stat.wisc.edu/~jgillett/451/data/kaggle_titanic_train.csv', engine='python')\n",
    "\n",
    "feature_names = ['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch']\n",
    "df = df[feature_names]\n",
    "\n",
    "print('First 7 Rows: ')\n",
    "print(df.loc[:6,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fda2ee",
   "metadata": {},
   "source": [
    "### Try to train a $k$NN model to predict $y=$ 'Survived' from $X=$ these features: 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch'.\n",
    "- Use $k = 3$ and the (default) euclidean metric.\n",
    "- Notice at the bottom of the error message that it fails with the error \"ValueError: could not convert string to float: 'male'\".\n",
    "- Comment out your .fit() line so the cell can run without error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faf87ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch']\n",
    "X = df[feature_names].to_numpy()\n",
    "y = df['Survived'].to_numpy()\n",
    "\n",
    "# kNN\n",
    "k = 3\n",
    "clf = KNeighborsClassifier(n_neighbors=k, metric='euclidean')\n",
    "# clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74eea90e",
   "metadata": {},
   "source": [
    "### Try to train again, this time without the 'Sex' feature.\n",
    "- Notice that it fails because \"Input contains NaN\".\n",
    "- Comment out your .fit() line so the cell can run without error.\n",
    "- Run `X.isna().any()` (where X is the name of your DataFrame of features) to see that\n",
    "  the 'Age' feature has missing values. (You can see the first missing value in\n",
    "  the sixth row that you displayed above.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4032cc0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m feature_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPclass\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSibSp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mParch\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 2\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m[feature_names]\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[0;32m      3\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSurvived\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[0;32m      5\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "feature_names = ['Pclass', 'Age', 'SibSp', 'Parch']\n",
    "X = df[feature_names].to_numpy()\n",
    "y = df['Survived'].to_numpy()\n",
    "\n",
    "k = 3\n",
    "clf = KNeighborsClassifier(n_neighbors=k, metric='euclidean')\n",
    "# clf.fit(X, y)\n",
    "df[feature_names].isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b103b9",
   "metadata": {},
   "source": [
    "### 1d. Train without the 'Sex' and 'Age' features.\n",
    "- Report accuracy on the training data with a line of the form\n",
    "  `Accuracy on training data is  0.500` (0.500 may not be correct)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e626bdee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data is 0.664\n"
     ]
    }
   ],
   "source": [
    "# ... your code here ...\n",
    "feature_names = ['Pclass', 'SibSp', 'Parch']\n",
    "X = df[feature_names].to_numpy()\n",
    "y = df['Survived'].to_numpy()\n",
    "\n",
    "k = 3\n",
    "clf = KNeighborsClassifier(n_neighbors=k, metric='euclidean')\n",
    "clf.fit(X, y)\n",
    "print(f'Accuracy on training data is {clf.score(X, y):.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b617602",
   "metadata": {},
   "source": [
    "### 1e.  Use one-hot encoding\n",
    "to include a binary 'male'  feature made from the 'Sex' feature. (Or include a binary 'female'\n",
    "feature, according to your preference. Using both is unnecessary since either is the logical\n",
    "negation of the other.) That is, train on these features: 'Pclass', 'SibSp', 'Parch', 'male'.\n",
    "- Use pandas's df.join(pd.get_dummies())`.\n",
    "- Report training accuracy as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71d04e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data is 0.744\n"
     ]
    }
   ],
   "source": [
    "# ... your code here ...\n",
    "df = pd.read_csv('http://www.stat.wisc.edu/~jgillett/451/data/kaggle_titanic_train.csv', engine='python')\n",
    "feature_names = ['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch']\n",
    "df = df[feature_names]\n",
    "\n",
    "df = df.join(pd.get_dummies(df.Sex, drop_first=True))\n",
    "\n",
    "feature_names = ['Pclass', 'SibSp', 'Parch', 'male']\n",
    "X = df[feature_names].to_numpy()\n",
    "y = df['Survived'].to_numpy()\n",
    "\n",
    "k = 3\n",
    "clf = KNeighborsClassifier(n_neighbors=k, metric='euclidean')\n",
    "clf.fit(X, y)\n",
    "print(f'Accuracy on training data is {clf.score(X, y):.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210618af",
   "metadata": {},
   "source": [
    "### 1f. Use data imputation\n",
    "to include an 'age' feature made from 'Age' but replacing each missing value with the median\n",
    "of the non-missing ages. That is, train on these features: 'Pclass', 'SibSp', 'Parch', 'male',\n",
    "'age'.\n",
    "\n",
    "- Report training accuracy as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0753fb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data is 0.863\n"
     ]
    }
   ],
   "source": [
    "# ... your code here ...\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='median', fill_value=None)\n",
    "df['age'] = imp.fit_transform(df.Age.to_numpy().reshape(-1,1)) \n",
    "\n",
    "feature_names = ['Pclass', 'SibSp', 'Parch', 'male', 'age']\n",
    "X = df[feature_names].to_numpy()\n",
    "y = df['Survived'].to_numpy()\n",
    "\n",
    "k = 3\n",
    "clf = KNeighborsClassifier(n_neighbors=k, metric='euclidean')\n",
    "clf.fit(X, y)\n",
    "print(f'Accuracy on training data is {clf.score(X, y):.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9050084a",
   "metadata": {},
   "source": [
    "## 2. Explore model fit, overfit, and regularization in the context of multiple linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715fc1b2",
   "metadata": {},
   "source": [
    "### 2a. Prepare the data:\n",
    "- Read [http://www.stat.wisc.edu/~jgillett/451/data/mtcars.csv](http://www.stat.wisc.edu/~jgillett/451/data/mtcars.csv) into a DataFrame.\n",
    "- Set a variable `X` to the subset consisting of all columns except `mpg`.\n",
    "- Set a variable `y` to the `mpg` column.\n",
    "- Use `train_test_split()` to split `X` and `y` into `X_train`, `X_test`, `y_train`, and `y_test`.\n",
    "  - Reserve half the data for training and half for testing.\n",
    "  - Use `random_state=0` to get reproducible results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbf49fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... your code here ...\n",
    "df = pd.read_csv('http://www.stat.wisc.edu/~jgillett/451/data/mtcars.csv', engine='python', index_col=0)\n",
    "df = df.rename({'Unnamed: 0': 'brand'}, axis='columns')\n",
    "\n",
    "X=df.drop(columns=['mpg']).to_numpy()\n",
    "y = df.mpg.to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1b3e11",
   "metadata": {},
   "source": [
    "### 2b. Train three models on the training data and evaluate each on the test data:\n",
    "- `LinearRegression()`\n",
    "- `Lasso()`\n",
    "- `Ridge()`\n",
    "\n",
    "The evaluation consists in displaying MSE$_\\text{train}, $ MSE$_\\text{test}$, and the coefficients $\\mathbf{w}$ for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb40699b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                model  MSE_train  MSE_test  .intercept_  \\\n",
      "0  LinearRegression()       0.39     30.23       -70.30   \n",
      "1             Lasso()       5.69     12.99        33.80   \n",
      "2             Ridge()       1.99     11.20         7.25   \n",
      "\n",
      "                                              .coef_  \n",
      "0  [0.03, 0.03, 3.13, -7.34, 3.93, -4.09, -1.22, ...  \n",
      "1  [-0.04, -0.02, 0.0, -0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "2  [-0.01, 0.0, 0.79, -3.22, 1.1, -0.48, 0.47, 1....  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ren\\AppData\\Local\\Temp\\ipykernel_12448\\4196530819.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'model': model, 'MSE_train': MSE_train,\n",
      "C:\\Users\\Ren\\AppData\\Local\\Temp\\ipykernel_12448\\4196530819.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'model': model, 'MSE_train': MSE_train,\n",
      "C:\\Users\\Ren\\AppData\\Local\\Temp\\ipykernel_12448\\4196530819.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'model': model, 'MSE_train': MSE_train,\n"
     ]
    }
   ],
   "source": [
    "# ... your code here ...\n",
    "models = [linear_model.LinearRegression(), linear_model.Lasso(), linear_model.Ridge()]\n",
    "df = pd.DataFrame(columns=['model', 'MSE_train', 'MSE_test', '.intercept_', '.coef_'])\n",
    "\n",
    "for model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    MSE_train = (1/y_train.size) * np.sum((y_train - model.predict(X_train))**2)\n",
    "    MSE_test = (1/y_test.size)  * np.sum((y_test - model.predict(X_test))**2)\n",
    "    df = df.append(pd.DataFrame({'model': model, 'MSE_train': MSE_train,\n",
    "                                 'MSE_test': MSE_test, '.intercept_': model.intercept_,\n",
    "                                 # I'm not showing .coef_[0], always 0 here, absorbed by .intercept_\n",
    "                                 '.coef_': [np.round(model.coef_[1:], 2)]}), # round for display\n",
    "                   ignore_index=True)\n",
    "pd.set_option('display.precision', 2)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523ff587",
   "metadata": {},
   "source": [
    "### 2c. Answer a few questions about the models:\n",
    "- Which one best fits the training data?\n",
    "- Which one best fits the test data?\n",
    "- Which one does feature selection by setting most coefficients to zero?- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36efeef7-abf7-4424-97e0-36f7b1bd16cb",
   "metadata": {},
   "source": [
    "# ... your answers here in a markdown cell ...\n",
    "1. Linear Regression fits the training data the best\n",
    "2. Ridge Regression fits the test data the best\n",
    "3. Lasso Regression did feature selection by setting most coefficients to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8b2878-5153-4a55-bc72-8a0d954a21e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
